0:00:01.390,0:00:06.600
Hello everyone, welcome to the third XSCALE Alliance webinar on the principles of agile

0:00:07.299,0:00:08.590
organization.

0:00:08.590,0:00:12.210
My name is Peter Merel. In our previous webinars,

0:00:12.210,0:00:18.569
we discussed stacking growth curves for exponential return on investment and the principle and practice of designing for simplicity.

0:00:19.660,0:00:27.449
Today we'll look at how an agile organization prioritizes design to continuously optimize throughput. A goal that Eli Goldratt described as

0:00:27.760,0:00:29.619
opening the bottleneck.

0:00:29.619,0:00:36.058
Goldratt was the father of throughput accounting - an alternative to cost accounting with general application throughout the worlds of business and engineering.

0:00:38.079,0:00:43.558
Anything with the word accounting and it tends to turn Agilists off, but if you have an agile mindset,

0:00:43.559,0:00:46.199
I promise this throughput stuff will astonish you.

0:00:47.530,0:00:55.050
You're looking at a Gantt chart - the backbone of traditional management and cost accounting. It represents three kinds of constraints: time,

0:00:55.449,0:00:57.449
operating expense, and scope.

0:00:57.789,0:01:03.119
The most constrained part of this chart is called the critical path, and it's colored in crimson here.

0:01:04.030,0:01:10.140
Goldratt said business decisions must account for many more constraints than just those three.

0:01:11.680,0:01:13.680
This "Theory of Constraints"

0:01:13.810,0:01:19.740
says that in any system of production, at any time, there is always a single dominant constraint.

0:01:20.680,0:01:22.680
Goldratt called it the bottleneck.

0:01:22.930,0:01:29.009
By definition, any work done to open a constraint that isn't currently the bottleneck can't affect throughput.

0:01:30.850,0:01:36.519
As throughput doesn't turn up on a Gantt chart - and actually most constraints don't turn up on a Gantt chart - 

0:01:37.130,0:01:40.479
Gantt charts can't possibly generate logical business decisions.

0:01:41.479,0:01:43.479
Let's look at where they go off the rails.

0:01:43.670,0:01:51.519
This is an agile burndown chart. The horizontal axis represents time. The vertical represents delivery of valuable changes to system behaviors.

0:01:52.070,0:01:55.989
The green curve represents a team's progress in actually doing this.

0:01:57.440,0:02:03.399
Because humans aren't very good at predicting the future this green curve is wildly unrealistic.

0:02:04.009,0:02:06.579
Teams often see something more like this blue one.

0:02:08.720,0:02:16.209
Discovering their progress isn't going to satisfy expectations raised by their initial estimates, the team begins working weekends and evenings.

0:02:16.940,0:02:21.279
Fatigue causes errors and rework that soon kills any gain in productivity.

0:02:21.980,0:02:26.200
Management adds devs to help pick up the pace, which triggers Brooks' law -

0:02:27.769,0:02:31.629
adding resource to a late project makes it later.

0:02:33.019,0:02:39.099
A Smarter team might experience this purple curve. Seeing that their throughput is constrained, they reflect on the bottleneck.

0:02:39.950,0:02:46.509
Let's say that they're a software delivery team who started out with pure scrum. Their productivity is getting killed by manual testing.

0:02:47.390,0:02:51.850
They decide to invest time introducing BDD heroically hitting their estimates.

0:02:53.150,0:02:57.820
The problem with a Gantt chart is it confuses these two very different behaviors.

0:02:58.010,0:03:02.049
It doesn't provide any reason to behave logically like the team on the purple curve.

0:03:03.910,0:03:10.020
Determined to hit the green curve, it's regrettably still commonplace for managers to whip their teams onto the blue one.

0:03:11.470,0:03:16.470
Let's turn this burndown chart into a burn-up chart so we can understand what's going on

0:03:16.840,0:03:19.350
continuously and not just up to a fixed release date.

0:03:19.350,0:03:25.619
And let's look at another possible behavior for the team. Which is better: the red curve or the green curve?

0:03:27.250,0:03:33.270
Well if the green curve is possible, this part of the red curve must represent some kind of waste,

0:03:33.550,0:03:40.589
which the lean guys called Muda. It might be inevitable waste; perhaps caused by a dependency on an upstream team or

0:03:40.959,0:03:42.959
an influenza virus.

0:03:43.360,0:03:46.260
And this part of the curve, which lean calls Muri,

0:03:46.959,0:03:54.059
represents overburden. We know it's overburden, because the team wasn't able to maintain its velocity and fell back to the black line.

0:03:55.780,0:04:00.510
Typically overburden and waste occur in cycles, like a drunk staggering from step to step.

0:04:01.120,0:04:05.520
Lean calls this Mura, which means 'irregularity' or 'wobble'.

0:04:06.700,0:04:10.649
The agile manifesto stands against this with its principle of sustainable pace.

0:04:11.769,0:04:14.789
Clearly the green curve is a lot less wobbly than the red one.

0:04:15.519,0:04:21.959
Indeed it's leaner. But both curves meet expectations in the end, so why do we think the red one is worse?

0:04:25.330,0:04:29.879
Periods of overburden inevitably involve longer hours and increased stress.

0:04:30.640,0:04:37.529
Corners may not be intentionally cut, but under such conditions it's inevitable that some design decisions are made in haste.

0:04:39.970,0:04:46.080
A repeating cycle of overburden makes shortcuts and mistakes mount up to generate technical debt.

0:04:47.950,0:04:53.189
Tech debt earns interest in the form of an exponential increase in the cost of change.

0:04:54.220,0:05:00.720
Agile delivery is only sustainable, when we continuously pay down this debt through merciless refactoring.

0:05:01.900,0:05:07.620
But there's something strange about this now. No matter how lean the curve there's less throughput.

0:05:08.230,0:05:15.960
Just like the Gantt chart before it, the burn-up chart hides a logical flaw in the way we're measuring things that will inevitably lead to

0:05:16.630,0:05:18.630
illogical behavior.

0:05:18.760,0:05:22.619
This flaw has to do with the very definition of throughput.

0:05:24.490,0:05:27.810
Controlling throughput is well understood in the domain of industrial design.

0:05:28.450,0:05:35.400
This is Maxwell's governor from the 19th century. The faster the steam exits the pipe, the faster the balls spin round.

0:05:35.710,0:05:43.319
Centripetal force moves the assembly of levers to throttle the pipe, resulting in a continuously sustained flow, no matter how hot the fire.

0:05:45.040,0:05:48.270
This is Don Wells' 20th century diagram of extreme programming.

0:05:49.150,0:05:53.339
XP was inspired by Beck's famous desire "to turn all the knobs to 10".

0:05:54.220,0:06:01.110
These are the knobs - they're all feedback loops like the steam governor. They work to generate a continuously sustained flow of code.

0:06:02.080,0:06:06.659
By measuring the delivery of story points over time, we can project release dates.

0:06:09.780,0:06:15.979
Stories are continuously integrated into the codebase and the whole is continuously refactored to minimize technical debt.

0:06:18.770,0:06:22.720
Well, which one of these curves represents actual business throughput?

0:06:24.680,0:06:28.150
Wait, not so fast, there is more to put on this dashboard.

0:06:30.910,0:06:34.499
Obviously, the work of delivering stories has to fit inside operating expense.

0:06:36.880,0:06:43.709
Features are groups of stories that provide customer value as a whole. Features are the atoms of release planning.

0:06:44.349,0:06:48.599
Figuring out their budgets and priorities is also work that draws from operating expense.

0:06:49.780,0:06:54.750
We must continuously adapt feature acceptance tests to learnings from design and analytic work.

0:06:56.890,0:07:04.590
Whenever these learnings mean the story burner won't fit within the feature budgets of the release plan, we need to refactor the release plan.

0:07:05.080,0:07:07.080
This requires whole board thinking,

0:07:07.630,0:07:09.630
reprioritizing for maximum return.

0:07:12.490,0:07:16.319
So we enter the realm of cost accounting, where to describe throughput

0:07:16.360,0:07:23.430
we need only understand one number: the return on the investment. Or in other words: the cost per unit of revenue.

0:07:27.410,0:07:29.980
Oops! Remember this guy from our first webinar?

0:07:31.040,0:07:37.420
Exponential, and then entropic return on investment? How do we relate this to all the jagged curves that we're just looking at?

0:07:38.870,0:07:46.059
In our second webinar we saw how the return on a product breaks out into five metrics on its service ecosystem.

0:07:46.060,0:07:50.890
Now, let's get a little bit more empirical with these and provide an example of how we could measure and project them.

0:07:52.300,0:07:54.900
You can pause here and go through this table at your leisure.

0:07:55.300,0:08:01.469
The idea is simply that, if on average 10% of the people you acquire wind up generating 10 dollars of return,

0:08:01.810,0:08:04.620
you can value each person you acquire at $1.

0:08:06.660,0:08:10.969
That's simplistic and these curves are far smoother than any we actually measure,

0:08:11.190,0:08:15.350
but this little model serves to help us understand these things as constraints.

0:08:16.050,0:08:22.669
If we halve the number of customers we acquire, that halves the number we can activate and retain and the rate of referrals and the

0:08:22.669,0:08:23.910
amount of revenue.

0:08:23.910,0:08:26.749
This is customer acquisition as a bottleneck

0:08:28.380,0:08:30.120
The same effect occurs when

0:08:30.120,0:08:36.080
activation is the bottleneck. While acquiring more customers may bump the rest up linearly, if the majority are being lost through

0:08:36.479,0:08:41.299
failing to activate, there's little point in acquiring more. We'll just poison the market that way.

0:08:42.659,0:08:44.718
Likewise if the bottleneck is in retention.

0:08:45.240,0:08:52.609
Work done on acquisition or activation features won't stop the bleeding and work on referral and revenue features can't achieve any

0:08:52.830,0:08:54.830
significant effect.

0:08:55.140,0:08:59.839
Referrals dominate the rate at which an ecosystem can grow and thereby its revenue.

0:09:00.390,0:09:04.429
And shortcomings in initial revenue generating experiences, may bottleneck the subsequent ones.

0:09:07.740,0:09:11.930
So it's clear now that there's no such thing as a fixed cost per unit of revenue.

0:09:13.230,0:09:21.020
Instead throughput is about the area under the curve, and this is the jumping off point for Goldratt's method of throughput accounting.

0:09:22.620,0:09:27.289
Just like in cost accounting, we have revenue and operating expense. The Theory of Constraints

0:09:27.690,0:09:32.359
gives us some new names for some other cost accounting terminology, but that's not the point.

0:09:33.780,0:09:40.399
Goldratt distinguishes between operating expenses and what he calls truly variable costs. Things whose costs we can project,

0:09:40.530,0:09:43.309
but which can't be improved by any work we do.

0:09:44.840,0:09:47.199
What's left is the net profit. If

0:09:47.630,0:09:53.200
revenue represents customer value and operating expense represents employee value, net profit

0:09:53.450,0:09:58.150
Represents the owners value. They balance this against their investment in establishing the business.

0:10:00.020,0:10:06.850
So throughput accounting defines throughput as net profit plus operating expense, and that's what we've been missing;

0:10:06.850,0:10:09.009
that's what we're actually trying to optimize.

0:10:11.820,0:10:14.269
Alright then, let's see what difference it makes.

0:10:15.060,0:10:22.250
Oh, look at that nasty blue system integration testing curve at the bottom of the operating expense. You can see it's going exponential.

0:10:23.279,0:10:29.509
So now costs are spiraling and technical debt threatens to eat up all the delivery bandwidth and kill productivity.

0:10:30.269,0:10:33.559
That's gonna make a nasty constraint well. Let's fix it.

0:10:35.399,0:10:41.839
Not only was that good for productivity, but by reducing staff costs it was good for the net profit too.

0:10:42.390,0:10:45.890
Except, did you notice it didn't change throughput at all?

0:10:56.270,0:11:00.309
In fact this is the cost accounting equivalent of a farmer eating his seed corn.

0:11:00.310,0:11:07.479
And it's a common misunderstanding of the lean principles. If our first focus is reducing operating expense to the bare minimum

0:11:07.480,0:11:13.209
we need for efficient delivery, we'll never retain the learning or the bandwidth we have to have to lift throughput.

0:11:15.320,0:11:22.809
Instead of cutting expense, we should exploit the fact that no constraint other than the immediate bottleneck can have a significant effect on throughput.

0:11:23.000,0:11:30.399
That means if we simply maintain operating expense, we can redirect a lot of resource into research and design work

0:11:30.500,0:11:37.659
to generate the innovation we need to open the market bottleneck - which ever pirate metric represents that at the moment.

0:12:02.250,0:12:07.429
In fact, we'll need to run market analytics continuously so we can respond immediately

0:12:07.920,0:12:14.660
to whatever constraint goes bottleneck from time to time. That's always the critical priority for design.

0:12:16.200,0:12:21.289
But now we've lifted this first bottleneck, perhaps this is the time to minimize the operating expense.

0:12:22.170,0:12:29.840
On the other hand, by definition, once we've lifted one bottleneck a different constraint becomes a new bottleneck.

0:12:31.290,0:12:37.550
We'd only cut operating expense if we had no more market or solution or organization bottlenecks to open.

0:12:37.920,0:12:42.289
If anything, our owners should be motivated to reinvest their net profits to increase

0:12:42.780,0:12:46.399
operating expense in order to accelerate the attack on the next bottleneck.

0:12:47.790,0:12:52.130
This might be a geographic constraint, or segment constraint on our market.

0:12:52.130,0:12:59.780
We can prioritize design to lift those, or go the full Steve Jobs and prioritize design to open a whole new service ecosystem.

0:13:00.060,0:13:05.060
Leaving our competition to struggle in old markets while we sail for new ones.

0:13:27.180,0:13:33.380
Before we get entirely carried away with such a romantic view, let's consider throughput numbers in a different light.

0:13:33.540,0:13:35.540
As we saw in our second webinar,

0:13:35.610,0:13:41.419
we must use science as an integral part of our design process to validate assumptions as we go.

0:13:41.850,0:13:49.579
This isn't about some kind of Big Bang magical thinking. It's about iterative, reductive, build-measure-learn and refactor.

0:13:50.190,0:13:53.720
But there is a larger problem an agile organization must solve.

0:13:54.570,0:14:02.479
Certainly a clear-eyed scientific and continuous numerical understanding of throughput provides a much better basis for business decisions than with cost accounting.

0:14:03.240,0:14:09.680
But that's assuming our organization has a logical process of decision making that can be learn from these analytics and metrics.

0:14:11.370,0:14:16.250
Unfortunately here in the first half of the 21st century, this isn't a safe assumption.

0:14:19.380,0:14:27.320
Happily, there's a good agile solution to this problem. One our agile delivery teams use every day without even thinking about it.

0:14:27.320,0:14:32.840
And one that Hiawatha proved can scale to hundreds of thousands and operate sustainably for hundreds of years.

0:14:34.200,0:14:39.290
We'll explore this territory in our fourth webinar on the principles of agile organization:

0:14:39.990,0:14:42.530
autonomous teams in holarchic streams.

0:14:43.650,0:14:49.129
If you'd like to get involved more deeply with these ideas try XScaleAlliance.org.

0:14:49.890,0:14:52.009
We look forward to your company next time!
